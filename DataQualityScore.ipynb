{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279bb18d-0812-417d-88d7-a75d26c5a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Quality Score: 0.400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/peterripperger/Desktop/Startup/data/Initial Products/shopping_trends.csv\")\n",
    "\n",
    "# Automatically detect numeric and non-numeric columns\n",
    "numeric_X = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# 1. Calculate Multicollinearity (VIF)\n",
    "if not numeric_X.empty:\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = numeric_X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(numeric_X.values, i) for i in range(numeric_X.shape[1])]\n",
    "else:\n",
    "    vif_data = pd.DataFrame(columns=['Feature', 'VIF'])\n",
    "\n",
    "# 2. Calculate Coefficient of Variation (CV)\n",
    "cv_data = df.std(numeric_only=True) / df.mean(numeric_only=True)\n",
    "\n",
    "# 3. Calculate Entropy\n",
    "def calculate_entropy(series):\n",
    "    proportions = series.value_counts(normalize=True)\n",
    "    return -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "entropy_data = df.apply(calculate_entropy)\n",
    "\n",
    "# 4. Feature Relevance (Mutual Information)\n",
    "# For simplicity in a fully automated workflow, mutual information considers all columns\n",
    "if not numeric_X.empty:\n",
    "    mi_scores = mutual_info_classif(numeric_X, pd.Series(np.zeros(len(numeric_X))), discrete_features=False)\n",
    "    mi_data = pd.Series(mi_scores, index=numeric_X.columns)\n",
    "else:\n",
    "    mi_data = pd.Series(dtype=float)\n",
    "\n",
    "# 5. Gradient-Based Scoring\n",
    "def score_metric(value, lower_bound, upper_bound):\n",
    "    if value <= lower_bound:\n",
    "        return 0\n",
    "    elif value >= upper_bound:\n",
    "        return 1\n",
    "    elif lower_bound < value < upper_bound:\n",
    "        return 1\n",
    "    else:\n",
    "        return (value - lower_bound) / (upper_bound - lower_bound)\n",
    "\n",
    "# Calculate individual scores\n",
    "if not vif_data.empty:\n",
    "    vif_scores = vif_data['VIF'].apply(lambda x: score_metric(x, 1, 10))  # VIF range: 1 to 5\n",
    "else:\n",
    "    vif_scores = pd.Series(dtype=float)\n",
    "\n",
    "cv_scores = cv_data.apply(lambda x: score_metric(x, 0.05, 2))  # CV range: 0.1 to 1\n",
    "entropy_scores = entropy_data.apply(lambda x: score_metric(x, 0.5, 1))  # Entropy range: 0.7 to 1\n",
    "\n",
    "# Combine metrics into weighted score\n",
    "vif_weight = 0.4\n",
    "cv_weight = 0.2\n",
    "entropy_weight = 0.4\n",
    "\n",
    "weighted_scores = pd.Series(0, index=df.columns)\n",
    "if not vif_scores.empty:\n",
    "    weighted_scores.update(vif_scores * vif_weight)\n",
    "if not cv_scores.empty:\n",
    "    weighted_scores.update(cv_scores * cv_weight)\n",
    "if not entropy_scores.empty:\n",
    "    weighted_scores.update(entropy_scores * entropy_weight)\n",
    "\n",
    "# Final dataset quality score\n",
    "final_score = weighted_scores.mean()\n",
    "\n",
    "# Print the final dataset quality score\n",
    "print(f\"Final Dataset Quality Score: {final_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a09707-7b8c-4a3e-9bc3-452e6cdc1dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF Scores:\n",
      "0    0.00000\n",
      "1    0.00000\n",
      "2    0.00000\n",
      "3    0.47234\n",
      "4    0.00000\n",
      "5    1.00000\n",
      "Name: VIF, dtype: float64\n",
      "CV Scores:\n",
      "Severity                     0.841397\n",
      "Noise Aug Temperature(F)     0.864445\n",
      "Noise Aug Wind_Chill(F)      0.872783\n",
      "Noise Aug Humidity(%)        0.872603\n",
      "Noise Aug Pressure(in)       0.809820\n",
      "Noise Aug Wind_Speed(mph)    0.947251\n",
      "dtype: float64\n",
      "Entropy Scores:\n",
      "Severity                     0.648961\n",
      "Noise Aug Temperature(F)     1.000000\n",
      "Noise Aug Wind_Chill(F)      1.000000\n",
      "Noise Aug Humidity(%)        1.000000\n",
      "Noise Aug Pressure(in)       1.000000\n",
      "Noise Aug Wind_Speed(mph)    1.000000\n",
      "Aug Sunrise_Sunset           0.898436\n",
      "Aug Civil_Twilight           0.795443\n",
      "Aug Nautical_Twilight        0.703225\n",
      "Aug Astronomical_Twilight    0.565514\n",
      "dtype: float64\n",
      "Weighted Scores:\n",
      "Severity                     0.324480\n",
      "Noise Aug Temperature(F)     0.500000\n",
      "Noise Aug Wind_Chill(F)      0.500000\n",
      "Noise Aug Humidity(%)        0.500000\n",
      "Noise Aug Pressure(in)       0.500000\n",
      "Noise Aug Wind_Speed(mph)    0.500000\n",
      "Aug Sunrise_Sunset           0.449218\n",
      "Aug Civil_Twilight           0.397721\n",
      "Aug Nautical_Twilight        0.351613\n",
      "Aug Astronomical_Twilight    0.282757\n",
      "dtype: float64\n",
      "Final Dataset Quality Score: 0.431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/peterripperger/Desktop/Startup/data/Initial Products/car_crash_augmented.csv\")\n",
    "\n",
    "# Automatically detect numeric and non-numeric columns\n",
    "numeric_X = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# 1. Calculate Multicollinearity (VIF)\n",
    "if not numeric_X.empty:\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = numeric_X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(numeric_X.values, i) for i in range(numeric_X.shape[1])]\n",
    "else:\n",
    "    vif_data = pd.DataFrame(columns=['Feature', 'VIF'])\n",
    "\n",
    "# 2. Calculate Coefficient of Variation (CV)\n",
    "cv_data = df.std(numeric_only=True) / df.mean(numeric_only=True)\n",
    "\n",
    "# 3. Calculate Entropy\n",
    "def calculate_entropy(series):\n",
    "    proportions = series.value_counts(normalize=True)\n",
    "    return -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "entropy_data = df.apply(calculate_entropy)\n",
    "\n",
    "# 4. Scoring Functions with Expanded Ranges\n",
    "def score_vif(value):\n",
    "    return max(0, min(1, 1 - (value - 5) / 10)) if value > 1 else 1  # Penalize VIF > 15 gradually\n",
    "\n",
    "def score_cv(value):\n",
    "    return max(0, min(1, 1 - abs(value - 1) / 5))  # Reward CV in range [0.01, 5]\n",
    "\n",
    "def score_entropy(value):\n",
    "    return max(0, min(1, (value - 0.3) / 0.7))  # Reward Entropy in range [0.3, 1]\n",
    "\n",
    "# Calculate individual scores\n",
    "if not vif_data.empty:\n",
    "    vif_scores = vif_data['VIF'].apply(score_vif)\n",
    "else:\n",
    "    vif_scores = pd.Series(dtype=float)\n",
    "\n",
    "cv_scores = cv_data.apply(score_cv)\n",
    "entropy_scores = entropy_data.apply(score_entropy)\n",
    "\n",
    "# Combine metrics into weighted score\n",
    "vif_weight = 0.2\n",
    "cv_weight = 0.3\n",
    "entropy_weight = 0.5\n",
    "\n",
    "weighted_scores = pd.Series(0, index=df.columns)\n",
    "if not vif_scores.empty:\n",
    "    weighted_scores.update(vif_scores * vif_weight)\n",
    "if not cv_scores.empty:\n",
    "    weighted_scores.update(cv_scores * cv_weight)\n",
    "if not entropy_scores.empty:\n",
    "    weighted_scores.update(entropy_scores * entropy_weight)\n",
    "\n",
    "# Final dataset quality score\n",
    "final_score = weighted_scores.mean()\n",
    "\n",
    "# Debug outputs\n",
    "print(f\"VIF Scores:\\n{vif_scores}\")\n",
    "print(f\"CV Scores:\\n{cv_scores}\")\n",
    "print(f\"Entropy Scores:\\n{entropy_scores}\")\n",
    "print(f\"Weighted Scores:\\n{weighted_scores}\")\n",
    "\n",
    "# Print the final dataset quality score\n",
    "print(f\"Final Dataset Quality Score: {final_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e24ca71d-e95f-45ec-aff9-2ebbe5a291f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the dependent variable (DV) column to drop:  Severity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF Scores:\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.472342\n",
      "3    0.000000\n",
      "4    1.000000\n",
      "Name: VIF, dtype: float64\n",
      "CV Scores:\n",
      "Noise Aug Temperature(F)     0.864445\n",
      "Noise Aug Wind_Chill(F)      0.872783\n",
      "Noise Aug Humidity(%)        0.872603\n",
      "Noise Aug Pressure(in)       0.809820\n",
      "Noise Aug Wind_Speed(mph)    0.947251\n",
      "dtype: float64\n",
      "Entropy Scores:\n",
      "Noise Aug Temperature(F)     1.000000\n",
      "Noise Aug Wind_Chill(F)      1.000000\n",
      "Noise Aug Humidity(%)        1.000000\n",
      "Noise Aug Pressure(in)       1.000000\n",
      "Noise Aug Wind_Speed(mph)    1.000000\n",
      "Aug Sunrise_Sunset           0.898436\n",
      "Aug Civil_Twilight           0.795443\n",
      "Aug Nautical_Twilight        0.703225\n",
      "Aug Astronomical_Twilight    0.565514\n",
      "dtype: float64\n",
      "Weighted Scores:\n",
      "Noise Aug Temperature(F)     0.500000\n",
      "Noise Aug Wind_Chill(F)      0.500000\n",
      "Noise Aug Humidity(%)        0.500000\n",
      "Noise Aug Pressure(in)       0.500000\n",
      "Noise Aug Wind_Speed(mph)    0.500000\n",
      "Aug Sunrise_Sunset           0.449218\n",
      "Aug Civil_Twilight           0.397721\n",
      "Aug Nautical_Twilight        0.351613\n",
      "Aug Astronomical_Twilight    0.282757\n",
      "dtype: float64\n",
      "Final Dataset Quality Score (excluding 'Severity'): 0.442\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/peterripperger/Desktop/Startup/data/Initial Products/car_crash_augmented.csv\")\n",
    "\n",
    "# Ask user for the dependent variable (DV) column to drop\n",
    "dv_column = input(\"Enter the name of the dependent variable (DV) column to drop: \").strip()\n",
    "\n",
    "# Ensure the DV column exists in the dataset\n",
    "if dv_column not in df.columns:\n",
    "    raise ValueError(f\"Column '{dv_column}' not found in the dataset.\")\n",
    "\n",
    "# Drop the DV column and separate features\n",
    "X = df.drop(columns=[dv_column])\n",
    "\n",
    "# Automatically detect numeric columns\n",
    "numeric_X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# 1. Calculate Multicollinearity (VIF)\n",
    "if not numeric_X.empty:\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = numeric_X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(numeric_X.values, i) for i in range(numeric_X.shape[1])]\n",
    "else:\n",
    "    vif_data = pd.DataFrame(columns=['Feature', 'VIF'])\n",
    "\n",
    "# 2. Calculate Coefficient of Variation (CV)\n",
    "cv_data = X.std(numeric_only=True) / X.mean(numeric_only=True)\n",
    "\n",
    "# 3. Calculate Entropy\n",
    "def calculate_entropy(series):\n",
    "    proportions = series.value_counts(normalize=True)\n",
    "    return -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "entropy_data = X.apply(calculate_entropy)\n",
    "\n",
    "# 4. Scoring Functions with Expanded Ranges\n",
    "def score_vif(value):\n",
    "    return max(0, min(1, 1 - (value - 5) / 10)) if value > 1 else 1  # Penalize VIF > 15 gradually\n",
    "\n",
    "def score_cv(value):\n",
    "    return max(0, min(1, 1 - abs(value - 1) / 5))  # Reward CV in range [0.01, 5]\n",
    "\n",
    "def score_entropy(value):\n",
    "    return max(0, min(1, (value - 0.3) / 0.7))  # Reward Entropy in range [0.3, 1]\n",
    "\n",
    "# Calculate individual scores\n",
    "if not vif_data.empty:\n",
    "    vif_scores = vif_data['VIF'].apply(score_vif)\n",
    "else:\n",
    "    vif_scores = pd.Series(dtype=float)\n",
    "\n",
    "cv_scores = cv_data.apply(score_cv)\n",
    "entropy_scores = entropy_data.apply(score_entropy)\n",
    "\n",
    "# Combine metrics into weighted score\n",
    "vif_weight = 0.2\n",
    "cv_weight = 0.3\n",
    "entropy_weight = 0.5\n",
    "\n",
    "weighted_scores = pd.Series(0, index=X.columns)\n",
    "if not vif_scores.empty:\n",
    "    weighted_scores.update(vif_scores * vif_weight)\n",
    "if not cv_scores.empty:\n",
    "    weighted_scores.update(cv_scores * cv_weight)\n",
    "if not entropy_scores.empty:\n",
    "    weighted_scores.update(entropy_scores * entropy_weight)\n",
    "\n",
    "# Final dataset quality score\n",
    "final_score = weighted_scores.mean()\n",
    "\n",
    "# Debug outputs\n",
    "print(f\"VIF Scores:\\n{vif_scores}\")\n",
    "print(f\"CV Scores:\\n{cv_scores}\")\n",
    "print(f\"Entropy Scores:\\n{entropy_scores}\")\n",
    "print(f\"Weighted Scores:\\n{weighted_scores}\")\n",
    "\n",
    "# Print the final dataset quality score\n",
    "print(f\"Final Dataset Quality Score (excluding '{dv_column}'): {final_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "185d1449-868f-4e52-a412-3d7072225542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the dependent variable (DV) column to drop:  187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF Scores:\n",
      "0      0.000000\n",
      "1      0.000000\n",
      "2      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "         ...   \n",
      "182    1.000000\n",
      "183    0.562549\n",
      "184    0.680163\n",
      "185    1.000000\n",
      "186    1.000000\n",
      "Name: VIF, Length: 187, dtype: float64\n",
      "CV Scores:\n",
      "0      1.000000\n",
      "1      1.000000\n",
      "2      1.000000\n",
      "3      1.000000\n",
      "4      1.000000\n",
      "         ...   \n",
      "182    0.000000\n",
      "183    0.000000\n",
      "184    0.000000\n",
      "185    0.130927\n",
      "186    0.466623\n",
      "Length: 187, dtype: float64\n",
      "Entropy Scores:\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "182    1\n",
      "183    1\n",
      "184    1\n",
      "185    1\n",
      "186    1\n",
      "Length: 187, dtype: int64\n",
      "Weighted Scores:\n",
      "0      0.5\n",
      "1      0.5\n",
      "2      0.5\n",
      "3      0.5\n",
      "4      0.5\n",
      "      ... \n",
      "182    0.5\n",
      "183    0.5\n",
      "184    0.5\n",
      "185    0.5\n",
      "186    0.5\n",
      "Length: 187, dtype: float64\n",
      "Final Dataset Quality Score (excluding '187'): 0.500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/peterripperger/Desktop/Startup/data/Initial Products/Augmented_ECG.csv\")\n",
    "\n",
    "# Ask user for the dependent variable (DV) column to drop\n",
    "dv_column = input(\"Enter the name of the dependent variable (DV) column to drop: \").strip()\n",
    "\n",
    "# Ensure the DV column exists in the dataset\n",
    "if dv_column not in df.columns:\n",
    "    raise ValueError(f\"Column '{dv_column}' not found in the dataset.\")\n",
    "\n",
    "# Drop the DV column and separate features\n",
    "X = df.drop(columns=[dv_column])\n",
    "\n",
    "# Automatically detect numeric columns\n",
    "numeric_X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# 1. Calculate Multicollinearity (VIF)\n",
    "if not numeric_X.empty:\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = numeric_X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(numeric_X.values, i) for i in range(numeric_X.shape[1])]\n",
    "else:\n",
    "    vif_data = pd.DataFrame(columns=['Feature', 'VIF'])\n",
    "\n",
    "# 2. Calculate Coefficient of Variation (CV)\n",
    "cv_data = X.std(numeric_only=True) / X.mean(numeric_only=True)\n",
    "\n",
    "# 3. Calculate Entropy\n",
    "def calculate_entropy(series):\n",
    "    proportions = series.value_counts(normalize=True)\n",
    "    return -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "entropy_data = X.apply(calculate_entropy)\n",
    "\n",
    "# 4. Scoring Functions with Desired Ranges\n",
    "def score_vif(value):\n",
    "    if 1 <= value <= 5:\n",
    "        return 1.0  # Full score within range\n",
    "    return max(0, min(1, 1 - abs(value - 5) / 10))  # Gradually reduce outside range\n",
    "\n",
    "def score_cv(value):\n",
    "    if 0.1 <= value <= 1:\n",
    "        return 1.0  # Full score within range\n",
    "    return max(0, min(1, 1 - abs(value - 1) / 5))  # Gradually reduce outside range\n",
    "\n",
    "def score_entropy(value):\n",
    "    if 0.7 <= value <= 1:\n",
    "        return 1.0  # Full score within range\n",
    "    return max(0, min(1, (value - 0.3) / 0.7))  # Gradually reduce outside range\n",
    "\n",
    "# Calculate individual scores\n",
    "if not vif_data.empty:\n",
    "    vif_scores = vif_data['VIF'].apply(score_vif)\n",
    "else:\n",
    "    vif_scores = pd.Series(dtype=float)\n",
    "\n",
    "cv_scores = cv_data.apply(score_cv)\n",
    "entropy_scores = entropy_data.apply(score_entropy)\n",
    "\n",
    "# Combine metrics into weighted score\n",
    "vif_weight = 0.2\n",
    "cv_weight = 0.3\n",
    "entropy_weight = 0.5\n",
    "\n",
    "weighted_scores = pd.Series(0, index=X.columns)\n",
    "if not vif_scores.empty:\n",
    "    weighted_scores.update(vif_scores * vif_weight)\n",
    "if not cv_scores.empty:\n",
    "    weighted_scores.update(cv_scores * cv_weight)\n",
    "if not entropy_scores.empty:\n",
    "    weighted_scores.update(entropy_scores * entropy_weight)\n",
    "\n",
    "# Final dataset quality score\n",
    "final_score = weighted_scores.mean()\n",
    "\n",
    "# Debug outputs\n",
    "print(f\"VIF Scores:\\n{vif_scores}\")\n",
    "print(f\"CV Scores:\\n{cv_scores}\")\n",
    "print(f\"Entropy Scores:\\n{entropy_scores}\")\n",
    "print(f\"Weighted Scores:\\n{weighted_scores}\")\n",
    "\n",
    "# Print the final dataset quality score\n",
    "print(f\"Final Dataset Quality Score (excluding '{dv_column}'): {final_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
